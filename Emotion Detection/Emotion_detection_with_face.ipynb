{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1270f499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      " Loading preprocessed data...\n",
      "\n",
      " Starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]: 100%|██████████| 191/191 [09:31<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Loss:1.8585 | Val Acc:0.3083 | Val F1:0.2495\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]: 100%|██████████| 191/191 [12:22<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2] Loss:1.6819 | Val Acc:0.4438 | Val F1:0.3560\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]: 100%|██████████| 191/191 [13:24<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3] Loss:1.6101 | Val Acc:0.4230 | Val F1:0.3502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]: 100%|██████████| 191/191 [10:23<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4] Loss:1.5720 | Val Acc:0.3943 | Val F1:0.3404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]: 100%|██████████| 191/191 [10:08<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5] Loss:1.5358 | Val Acc:0.4362 | Val F1:0.3819\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/50]: 100%|██████████| 191/191 [09:55<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6] Loss:1.5206 | Val Acc:0.4794 | Val F1:0.4092\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/50]: 100%|██████████| 191/191 [10:00<00:00,  3.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7] Loss:1.4782 | Val Acc:0.4758 | Val F1:0.4214\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/50]: 100%|██████████| 191/191 [4:17:19<00:00, 80.83s/it]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8] Loss:1.4812 | Val Acc:0.4415 | Val F1:0.3916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/50]: 100%|██████████| 191/191 [08:18<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9] Loss:1.4496 | Val Acc:0.4702 | Val F1:0.4080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/50]: 100%|██████████| 191/191 [07:56<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10] Loss:1.4469 | Val Acc:0.4936 | Val F1:0.4328\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/50]: 100%|██████████| 191/191 [07:37<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11] Loss:1.4250 | Val Acc:0.4738 | Val F1:0.4197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12/50]: 100%|██████████| 191/191 [07:39<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12] Loss:1.4090 | Val Acc:0.5048 | Val F1:0.4296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/50]: 100%|██████████| 191/191 [07:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13] Loss:1.3943 | Val Acc:0.5002 | Val F1:0.4370\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14/50]: 100%|██████████| 191/191 [07:42<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14] Loss:1.3923 | Val Acc:0.4517 | Val F1:0.4102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/50]: 100%|██████████| 191/191 [07:47<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15] Loss:1.3645 | Val Acc:0.4929 | Val F1:0.4375\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16/50]: 100%|██████████| 191/191 [07:38<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16] Loss:1.3592 | Val Acc:0.5236 | Val F1:0.4645\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/50]: 100%|██████████| 191/191 [07:48<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17] Loss:1.3453 | Val Acc:0.4909 | Val F1:0.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18/50]: 100%|██████████| 191/191 [07:41<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18] Loss:1.3462 | Val Acc:0.5084 | Val F1:0.4728\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/50]: 100%|██████████| 191/191 [07:40<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19] Loss:1.3529 | Val Acc:0.5183 | Val F1:0.4765\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20/50]: 100%|██████████| 191/191 [07:38<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20] Loss:1.3193 | Val Acc:0.5160 | Val F1:0.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/50]: 100%|██████████| 191/191 [07:44<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21] Loss:1.3071 | Val Acc:0.4705 | Val F1:0.4400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22/50]: 100%|██████████| 191/191 [07:45<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22] Loss:1.3265 | Val Acc:0.5242 | Val F1:0.4775\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/50]: 100%|██████████| 191/191 [07:38<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23] Loss:1.3106 | Val Acc:0.5203 | Val F1:0.4833\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24/50]: 100%|██████████| 191/191 [07:39<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24] Loss:1.3068 | Val Acc:0.5223 | Val F1:0.4790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/50]: 100%|██████████| 191/191 [07:51<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25] Loss:1.2736 | Val Acc:0.5364 | Val F1:0.4968\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26/50]: 100%|██████████| 191/191 [07:40<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26] Loss:1.2906 | Val Acc:0.5236 | Val F1:0.4869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/50]: 100%|██████████| 191/191 [07:38<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27] Loss:1.2840 | Val Acc:0.5302 | Val F1:0.4953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28/50]: 100%|██████████| 191/191 [07:43<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28] Loss:1.2735 | Val Acc:0.5354 | Val F1:0.5073\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/50]: 100%|██████████| 191/191 [07:46<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29] Loss:1.2586 | Val Acc:0.5298 | Val F1:0.4952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30/50]: 100%|██████████| 191/191 [07:44<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30] Loss:1.2636 | Val Acc:0.5153 | Val F1:0.5052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/50]: 100%|██████████| 191/191 [07:46<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31] Loss:1.2578 | Val Acc:0.5223 | Val F1:0.4948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32/50]: 100%|██████████| 191/191 [07:44<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32] Loss:1.2517 | Val Acc:0.5338 | Val F1:0.5073\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/50]: 100%|██████████| 191/191 [07:42<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33] Loss:1.2470 | Val Acc:0.5523 | Val F1:0.5109\n",
      " Saved best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34/50]: 100%|██████████| 191/191 [07:52<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34] Loss:1.2485 | Val Acc:0.5285 | Val F1:0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/50]: 100%|██████████| 191/191 [07:55<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35] Loss:1.2291 | Val Acc:0.5401 | Val F1:0.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36/50]: 100%|██████████| 191/191 [07:52<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36] Loss:1.2381 | Val Acc:0.5265 | Val F1:0.4966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/50]: 100%|██████████| 191/191 [07:47<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37] Loss:1.2410 | Val Acc:0.5387 | Val F1:0.5022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38/50]: 100%|██████████| 191/191 [07:48<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38] Loss:1.2283 | Val Acc:0.5394 | Val F1:0.4980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/50]: 100%|██████████| 191/191 [08:07<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39] Loss:1.2333 | Val Acc:0.5364 | Val F1:0.5037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40/50]: 100%|██████████| 191/191 [08:23<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40] Loss:1.2201 | Val Acc:0.5457 | Val F1:0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/50]: 100%|██████████| 191/191 [07:49<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41] Loss:1.2224 | Val Acc:0.5473 | Val F1:0.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42/50]: 100%|██████████| 191/191 [07:33<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42] Loss:1.2075 | Val Acc:0.5364 | Val F1:0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/50]: 100%|██████████| 191/191 [08:30<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43] Loss:1.2179 | Val Acc:0.5447 | Val F1:0.5083\n",
      " Early stopping\n",
      "\n",
      " Final Performance:\n",
      "Train Accuracy: 0.6172\n",
      "Test Accuracy:  0.5523\n",
      "Test F1-Score:  0.5109\n",
      "  Done!\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "import mediapipe as mp\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Paths & Dataset\n",
    "# ---------------------------\n",
    "train_path = r\"C:\\Ashvin\\AI ML\\Project\\Emotion Detection\\Data\\train\"\n",
    "test_path  = r\"C:\\Ashvin\\AI ML\\Project\\Emotion Detection\\Data\\test\"\n",
    "\n",
    "train_raw = datasets.ImageFolder(train_path)\n",
    "test_raw  = datasets.ImageFolder(test_path)\n",
    "\n",
    "with open(\"classes.json\", \"w\") as f:\n",
    "    json.dump(train_raw.classes, f)\n",
    "\n",
    "# ---------------------------\n",
    "# Face detection & landmarks\n",
    "# ---------------------------\n",
    "mtcnn = MTCNN(image_size=128, margin=10, keep_all=False, device=device)\n",
    "mp_face = mp.solutions.face_mesh\n",
    "\n",
    "def preprocess_faces(dataset, split):\n",
    "    print(f\" Preprocessing {split} set...\")\n",
    "    faces, labels, landmarks_all = [], [], []\n",
    "    with mp_face.FaceMesh(static_image_mode=True, max_num_faces=1) as fm:\n",
    "        for img, label in tqdm(dataset):\n",
    "            img_rgb = img.convert('RGB')\n",
    "            face_rgb = mtcnn(img_rgb)\n",
    "            if isinstance(face_rgb, list):\n",
    "                face_rgb = face_rgb[0] if len(face_rgb) > 0 else None\n",
    "            if face_rgb is None:\n",
    "                continue\n",
    "            np_face = (face_rgb.permute(1,2,0).cpu().numpy() * 255).astype(np.uint8)\n",
    "            results = fm.process(np_face)\n",
    "            if results.multi_face_landmarks:\n",
    "                landmarks = [(lm.x, lm.y, lm.z) for lm in results.multi_face_landmarks[0].landmark]\n",
    "                if len(landmarks) == 468:\n",
    "                    faces.append(face_rgb)\n",
    "                    labels.append(label)\n",
    "                    landmarks_all.append(landmarks)\n",
    "    print(f\" Collected {len(faces)} faces for {split}\")\n",
    "    return torch.stack(faces), torch.tensor(labels), landmarks_all\n",
    "\n",
    "if os.path.exists('ed_train_data.pt') and os.path.exists('ed_test_data.pt'):\n",
    "    print(\" Loading preprocessed data...\")\n",
    "    train_data = torch.load('ed_train_data.pt')\n",
    "    test_data  = torch.load('ed_test_data.pt')\n",
    "    train_faces, train_labels, train_landmarks = train_data['faces'], train_data['labels'], train_data['landmarks']\n",
    "    test_faces, test_labels, test_landmarks    = test_data['faces'],  test_data['labels'],  test_data['landmarks']\n",
    "else:\n",
    "    train_faces, train_labels, train_landmarks = preprocess_faces(train_raw, 'train')\n",
    "    test_faces, test_labels, test_landmarks    = preprocess_faces(test_raw, 'test')\n",
    "    torch.save({'faces': train_faces, 'labels': train_labels, 'landmarks': train_landmarks}, 'ed_train_data.pt')\n",
    "    torch.save({'faces': test_faces,  'labels': test_labels,  'landmarks': test_landmarks},  'ed_test_data.pt')\n",
    "\n",
    "# ---------------------------\n",
    "# Compute global mean/std for landmarks\n",
    "# ---------------------------\n",
    "all_landmarks = np.array([np.array(l).flatten() for l in train_landmarks])\n",
    "lm_mean = torch.tensor(all_landmarks.mean(axis=0), dtype=torch.float)\n",
    "lm_std  = torch.tensor(all_landmarks.std(axis=0), dtype=torch.float) + 1e-6\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset with stronger augmentation\n",
    "# ---------------------------\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, faces, labels, landmarks, augment=True, lm_mean=None, lm_std=None):\n",
    "        self.faces = faces\n",
    "        self.labels = labels\n",
    "        self.landmarks = landmarks\n",
    "        self.augment = augment\n",
    "        self.lm_mean = lm_mean\n",
    "        self.lm_std = lm_std\n",
    "        self.aug_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(128, scale=(0.8,1.0)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(0.2,0.15,0.15),\n",
    "            transforms.RandomApply([transforms.RandomAffine(10, translate=(0.1,0.1))], p=0.3),\n",
    "            transforms.RandomErasing(p=0.2, scale=(0.02,0.1)),  # new\n",
    "            transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "        ])\n",
    "        self.base_transform = transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
    "\n",
    "    def __len__(self): return len(self.faces)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        face = self.faces[idx]\n",
    "        landmarks = torch.tensor(np.array(self.landmarks[idx]).flatten(), dtype=torch.float)\n",
    "        landmarks = (landmarks - self.lm_mean) / self.lm_std\n",
    "        face = self.aug_transform(face) if self.augment else self.base_transform(face)\n",
    "        return face, landmarks, self.labels[idx]\n",
    "\n",
    "train_dataset = EmotionDataset(train_faces, train_labels, train_landmarks, augment=True, lm_mean=lm_mean, lm_std=lm_std)\n",
    "test_dataset  = EmotionDataset(test_faces,  test_labels,  test_landmarks, augment=False, lm_mean=lm_mean, lm_std=lm_std)\n",
    "\n",
    "# ---------------------------\n",
    "# DataLoader with balancing\n",
    "# ---------------------------\n",
    "class_counts = Counter(train_labels.numpy())\n",
    "median = np.median(list(class_counts.values()))\n",
    "class_weights = {k: median/v for k,v in class_counts.items()}\n",
    "sample_weights = [class_weights[l.item()] for l in train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# ---------------------------\n",
    "# Model: deeper classifier & landmark MLP\n",
    "# ---------------------------\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,padding=1), nn.BatchNorm2d(64), nn.LeakyReLU(0.1), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.LeakyReLU(0.1), nn.MaxPool2d(2), nn.Dropout(0.4),\n",
    "            nn.Conv2d(128,256,3,padding=1), nn.BatchNorm2d(256), nn.LeakyReLU(0.1), nn.AdaptiveAvgPool2d((4,4)), nn.Dropout(0.4)\n",
    "        )\n",
    "        self.landmark_mlp = nn.Sequential(\n",
    "            nn.Linear(1404, 256), nn.BatchNorm1d(256), nn.LeakyReLU(0.1), nn.Dropout(0.4)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256*4*4 + 256, 256), nn.BatchNorm1d(256), nn.LeakyReLU(0.1), nn.Dropout(0.4),\n",
    "            nn.Linear(256,128), nn.BatchNorm1d(128), nn.LeakyReLU(0.1), nn.Dropout(0.3),\n",
    "            nn.Linear(128,7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, landmarks):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        l = self.landmark_mlp(landmarks)\n",
    "        x = torch.cat([x, l], dim=1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = EmotionCNN().to(device)\n",
    "\n",
    "# ---------------------------\n",
    "# Optimizer & scheduler\n",
    "# ---------------------------\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)  # reduced smoothing\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# ---------------------------\n",
    "# Training loop\n",
    "# ---------------------------\n",
    "epochs, patience, best_f1, counter = 50, 10, 0, 0\n",
    "print(\"\\n Starting training\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss=0.0\n",
    "    for images, landmarks, labels in tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\"):\n",
    "        images, landmarks, labels = images.to(device), landmarks.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, landmarks)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss/len(train_loader)\n",
    "\n",
    "    # Eval with TTA\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, landmarks, labels in test_loader:\n",
    "            images, landmarks = images.to(device), landmarks.to(device)\n",
    "            outputs = model(images, landmarks)\n",
    "            outputs_flip = model(torch.flip(images,dims=[3]), landmarks)\n",
    "            outputs_mean = (outputs + outputs_flip)/2\n",
    "            _, preds = outputs_mean.max(1)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.numpy())\n",
    "\n",
    "    val_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    val_acc= accuracy_score(y_true, y_pred)\n",
    "    print(f\"Epoch [{epoch+1}] Loss:{avg_loss:.4f} | Val Acc:{val_acc:.4f} | Val F1:{val_f1:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_f1>best_f1:\n",
    "        best_f1, counter = val_f1, 0\n",
    "        torch.save(model.state_dict(), \"ed_final_best_model.pth\")\n",
    "        print(\" Saved best model\")\n",
    "    else:\n",
    "        counter+=1\n",
    "        if counter>=patience:\n",
    "            print(\" Early stopping\")\n",
    "            break\n",
    "\n",
    "# ---------------------------\n",
    "# Final evaluation\n",
    "# ---------------------------\n",
    "model.load_state_dict(torch.load(\"ed_final_best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "def evaluate(loader):\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, landmarks, labels in loader:\n",
    "            images, landmarks = images.to(device), landmarks.to(device)\n",
    "            outputs = model(images, landmarks)\n",
    "            outputs_flip = model(torch.flip(images,dims=[3]), landmarks)\n",
    "            outputs_mean = (outputs + outputs_flip)/2\n",
    "            _, preds = outputs_mean.max(1)\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.numpy())\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true,y_pred),\n",
    "        'precision': precision_score(y_true,y_pred,average='macro', zero_division=0),\n",
    "        'recall': recall_score(y_true,y_pred,average='macro', zero_division=0),\n",
    "        'f1': f1_score(y_true,y_pred,average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "train_metrics = evaluate(train_loader)\n",
    "test_metrics  = evaluate(test_loader)\n",
    "\n",
    "print(\"\\n Final Performance:\")\n",
    "print(f\"Train Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "print(f\"Test Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"Test F1-Score:  {test_metrics['f1']:.4f}\")\n",
    "\n",
    "with open(\"ed_final_train_metrics.json\",\"w\") as f: json.dump(train_metrics,f,indent=2)\n",
    "with open(\"ed_final_test_metrics.json\",\"w\") as f: json.dump(test_metrics,f,indent=2)\n",
    "\n",
    "print(\"  Done!\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
